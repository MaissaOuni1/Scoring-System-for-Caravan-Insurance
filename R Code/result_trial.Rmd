---
title: "**Assurance sur caravane**: cas d'étude de marketing ciblé"
author: "D-miners Group"
date: "November 18, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Présentation

La compagnie d’assurance canadienne AssurExperts Inc. <https://www.assurexperts.qc.ca> propose comme mission de définir une nouvelle stratégie publicitaire s’appuyant sur l’analyse des différents comportements des segments de clients, afin de détecter celui ou ceux qui paraissent les plus porteurs.

Notre mission consiste ainsi en deux tâches principales :

- Solliciter toutes les **catégories de clients** potentiellement intéressées par une police d’assurance sur caravane.

- Formuler une description méticuleuse sur les clients actuels et potentiels, et leurs degrés d’appétence pour souscrire à une police d’assurance sur caravane. Ca consiste ainsi en la définition d'un **profil bien précis** de la clientèle potentielle **typique** pour optimiser le ciblage des clients.

Notre premier objectif sera d'abord donc, d'en définir de ces tâches, les "data science goals" de notre étude.

## Objectifs Data Science

Dans ce cas d'étude, pour achever nos objectifs métier, on sera donc amené à passer par une étude des données bien précises, procéder par de bon "feature engineering" pour le "profiling" de la clientèle et enfin mettre en oeuvre un modèle opérant sur la définition des variables/attributs les plus importants pour notre cas d'étude pour classifier/déterminer les clients potentiels, ceci, peut être addressé par une bonne méthode de scoring clientel pour déterminer ce qu'on a définit en terme de métier par le "degré d'appétence".
Pour résumer ainsi, on se cèdera bien sûr de la méthode CRISP dans notre étude pour appliquer nos objectifs:

- Le feature engineering pour le **profiling** des clients potentiels

- La mise en oeuvre d'un modèle performant pour la classification de la clientèle et la détermination de leurs degrés d'appétance


## Chargement et compréhension des données
```{r echo=FALSE, message=FALSE}
setwd(dir = "/home/rkayx/Documents/Studies/ESPRIT/4thYear/Machine Learning/Labs/Lab2/Final_Analysis/")
#getwd()
library(psych)
library(knitr)
library(kableExtra)
library(magrittr)
library(plotly)
library(sqldf)
library(ggplot2)
library(plyr)
library(Hmisc)
library(mlbench)
library(caret)
library(MASS)
library(dplyr)
library(mlbench)
library(caret)
library(caretEnsemble)
```
``` {r}
raw_data <- read.delim("AssurancExpertsInc.txt")
```

``` {r echo=FALSE}
#str(raw_data)
kable(head(raw_data[1:15], 5), caption = "Visualisation de quelques colonnes pour une meilleure lisibilité") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```
<br>
Les données contiennent une gamme d’informations sur les clients, notamment le revenu, la tranche d’âge,
propriété du véhicule, nombre de polices souscrites et niveau des cotisations (primes) versées ainsi que
plus d'informations qualitatives sur le mode de vie et le type de ménage.

Avant toute analyse complémentaire, on va ignorer la variable 'STATUS' qui définit pour quelle finalité est adressée chaque observation, ceci est fait pour qu'après, en phase de modélisation, on procède par la méthode la plus appropriée pour ce tas de données, qui est le rééchantillonage et la validation croisée pour obtenir une meilleure précision dans notre modèle surtout qu'on essaiera de créer notre propre modèle de classification en empilant différents modèles et peaufinant leurs paramètres.

On procèdera aussi tout au long de notre étude par le principe de l'**immutabilité** des variables pour qu'on garantit la **non-perte** des données faute d'attention ou par mauvaise manipulation.

```{r}
prepared_data <- raw_data[1:ncol(raw_data)-1]
```
``` {r echo=FALSE}
kable(tail(prepared_data[71:86], 5), caption = "Visualisation de quelques colonnes pour une meilleure lisibilité") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```
<br>
Maintenant, pour une meilleure visualisation des données par objectif de compréhension, on s'est permis la modification des données et le 'décodage' des cases de la trâme pour qu'on puisse obtenir une meilleure visualisation au niveau des graphes obtenus.
```{r echo=FALSE}
viz_data <- read.delim("AssurancExpertsIncFinale.txt")
viz_data <- viz_data[1:86]
# The levels complete variables: MRELGE & PLEVEN
# Correcting/completing other variables' levels for visualization
levels(viz_data$MOSTYPE.) <- c(levels(viz_data$MOSTYPE.), "Junior cosmopolitan")
levels(viz_data$MRELSA) <- c(levels(viz_data$MRELSA), setdiff(levels(viz_data$MRELGE), levels(viz_data$MRELSA)))
levels(viz_data$MGODOV) <- c(levels(viz_data$MGODOV), setdiff(levels(viz_data$MRELGE), levels(viz_data$MGODOV)))
levels(viz_data$MBERZELF) <- c(levels(viz_data$MBERZELF), setdiff(levels(viz_data$MRELGE), levels(viz_data$MBERZELF)))
levels(viz_data$MAUT2.) <- c(levels(viz_data$MAUT2.), setdiff(levels(viz_data$MRELGE), levels(viz_data$MAUT2.)))
levels(viz_data$MINK123M) <- c(levels(viz_data$MINK123M), setdiff(levels(viz_data$MRELGE), levels(viz_data$MINK123M)))
levels(viz_data$MKOOPKLA) <- c(levels(viz_data$MKOOPKLA), setdiff(levels(viz_data$MRELGE), levels(viz_data$MKOOPKLA)))
levels(viz_data$PWAPART) <- c(levels(viz_data$PWAPART), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PWAPART)))
levels(viz_data$PWABEDR) <- c(levels(viz_data$PWABEDR), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PWABEDR)))
levels(viz_data$PWALAND) <- c(levels(viz_data$PWALAND), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PWALAND)))
levels(viz_data$PPERSAUT) <- c(levels(viz_data$PPERSAUT), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PPERSAUT)))
levels(viz_data$PBESAUT) <- c(levels(viz_data$PBESAUT), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PBESAUT)))
levels(viz_data$PMOTSCO) <- c(levels(viz_data$PMOTSCO), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PMOTSCO)))
levels(viz_data$PVRAAUT) <- c(levels(viz_data$PVRAAUT), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PVRAAUT)))
levels(viz_data$PAANHANG) <- c(levels(viz_data$PAANHANG), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PAANHANG)))
levels(viz_data$PTRACTOR) <- c(levels(viz_data$PTRACTOR), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PTRACTOR)))
levels(viz_data$PWERKT) <- c(levels(viz_data$PWERKT), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PWERKT)))
levels(viz_data$PBROM) <- c(levels(viz_data$PBROM), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PBROM)))
levels(viz_data$PPERSONG) <- c(levels(viz_data$PPERSONG), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PPERSONG)))
levels(viz_data$PGEZONG) <- c(levels(viz_data$PGEZONG), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PGEZONG)))
levels(viz_data$PWAOREG) <- c(levels(viz_data$PWAOREG), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PWAOREG)))
levels(viz_data$PBRAND) <- c(levels(viz_data$PBRAND), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PBRAND)))
levels(viz_data$PZEILPL) <- c(levels(viz_data$PZEILPL), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PZEILPL)))
levels(viz_data$PPLEZIER) <- c(levels(viz_data$PPLEZIER), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PPLEZIER)))
levels(viz_data$PFIETS) <- c(levels(viz_data$PFIETS), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PFIETS)))
levels(viz_data$PINBOED) <- c(levels(viz_data$PINBOED), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PINBOED)))
levels(viz_data$PBYSTAND) <- c(levels(viz_data$PBYSTAND), setdiff(levels(viz_data$PLEVEN), levels(viz_data$PBYSTAND)))
fig1 = table(viz_data$CLASS)
df1 = data.frame(fig1)
plot_ly(
  x = df1$Var1,
  y = df1$Freq,
  name = "CARAVAN",
  type = "bar"
)%>%
  layout(title  = "Intérêt en assurance sur caravane")
```
<br>
9239 On repondu par Non et 568 on accepté d’avoir une assurance sur caravane Il est clair que notre ensemble de données est très déséquilibré, avec seulement 5,9% des observations achetant réellement l’assurance. Avant de lancer notre analyse et de traiter les données non équilibrées, comprenons les caractéristiques des observations qui ont réellement acheté «l’assurance pour habitations mobiles». Comme il s’agit d’un problème de vente croisée, nous nous concentrerons davantage sur la compréhension des clients existants qui achètent généralement l’assurance.
```{r echo=FALSE, messages=FALSE}
df2 = sqldf("SELECT s.MOSHOOFD ,(SELECT count(*) FROM viz_data d1 WHERE CLASS='Yes' and s.MOSHOOFD  = d1.MOSHOOFD ) as 'NumberYes',(SELECT count(*) FROM viz_data d2 WHERE CLASS='No' and s.MOSHOOFD =d2.MOSHOOFD ) as 'NumberNo' FROM viz_data s GROUP BY s.MOSHOOFD ")
CustomerMainType <- df2$MOSHOOFD 
Yes <- df2$NumberYes
No <- df2$NumberNo
datadf2 <- data.frame(CustomerMainType, Yes, No)

plot_ly(datadf2, x = ~CustomerMainType, y = ~Yes, type = 'bar', name = 'Yes') %>%
  add_trace(y = ~No, name = 'No') %>%
  layout(yaxis = list(title = 'Count'), barmode = 'stack')
```
<br><br>
Dans le graphique à secteurs ci-dessus, les clients de divers types d’environ 10 étiquettes sont pris. Les clients appartenant à maintype 8 (familles avec adultes) et à maintype 2 (producteurs motivés) sont plus susceptibles d’acquérir la police Caravan.
<br><br>
```{r echo=FALSE, messages=FALSE}
df3 = sqldf("SELECT s.MSKB1 ,(SELECT count(*) FROM viz_data d1 WHERE CLASS='Yes' and s.MSKB1  = d1.MSKB1 ) as 'NumberYes',(SELECT count(*) FROM viz_data d2 WHERE CLASS='No' and s.MSKB1 =d2.MSKB1 ) as 'NumberNo' FROM viz_data s GROUP BY s.MSKB1 ")
SocialClassB1 <- df3$MSKB1 
Yes <- df3$NumberYes
No <- df3$NumberNo
datadf3 <- data.frame(SocialClassB1, Yes, No)
plot_ly(datadf3, x = ~SocialClassB1, y = ~Yes, type = 'bar', name = 'Yes') %>%
  add_trace(y = ~No, name = 'No') %>%
  layout(yaxis = list(title = 'Count'), barmode = 'stack')
df5 = sqldf("SELECT MSKB1 ,count(*) as 'Number' FROM viz_data WHERE CLASS='Yes' GROUP BY MSKB1 ")
plot_ly(
  x = df5$MSKB1 ,
  y = df5$Number,
  type = "bar"
) %>% layout(title="Social Class -> Yes")
```
<br><br
D’apres cette visualisation , on remarque que les client avec un SocialClass B1 entre 11-23 tend plus a avoir une assurance sur caravane.
<br><br>
```{r echo=FALSE, messages=FALSE}
df21 = sqldf("SELECT s.MBERARBG  ,(SELECT count(*) FROM viz_data d1 WHERE CLASS='Yes' and s.MBERARBG   = d1.MBERARBG  ) as 'NumberYes',(SELECT count(*) FROM viz_data d2 WHERE CLASS='No' and s.MBERARBG  =d2.MBERARBG  ) as 'NumberNo' FROM viz_data s GROUP BY s.MBERARBG  ")
SkilledLabourers <- df21$MBERARBG  
Yes <- df21$NumberYes
No <- df21$NumberNo
datadf21 <- data.frame(SocialClassB1, Yes, No)

plot_ly(datadf21, x = ~SkilledLabourers, y = ~Yes, type = 'bar', name = 'Yes') %>%
  add_trace(y = ~No, name = 'No') %>%
  layout(yaxis = list(title = 'Count'), barmode = 'stack')

df51 = sqldf("SELECT MBERARBG ,count(*) as 'Number' FROM viz_data WHERE CLASS='Yes' GROUP BY MBERARBG ")
plot_ly(
  x = df51$MBERARBG ,
  y = df51$Number,
  type = "bar"
) %>% layout(title="SkilledLabourers -> Yes")
```
<br><br>
On peur remarquer d’apres ce graph que les clients ouvriers talentueux avec une pourcentage de 11-23% et 24-36% et meme les non talentueux ouvriers tend a avoir une assurance sur caravane.
<br><br>
```{r echo=FALSE, messages=FALSE}
df22 = sqldf("SELECT s.PPERSAUT  ,(SELECT count(*) FROM viz_data d1 WHERE CLASS='Yes' and s.PPERSAUT   = d1.PPERSAUT  ) as 'NumberYes',(SELECT count(*) FROM viz_data d2 WHERE CLASS='No' and s.PPERSAUT  =d2.PPERSAUT  ) as 'NumberNo' FROM viz_data s GROUP BY s.PPERSAUT  ")
Contributioncarpolicies <- df22$PPERSAUT  
Yes <- df22$NumberYes
No <- df22$NumberNo
datadf22 <- data.frame(Contributioncarpolicies, Yes, No)
plot_ly(datadf22, x = ~Contributioncarpolicies, y = ~Yes, type = 'bar', name = 'Yes') %>%
  add_trace(y = ~No, name = 'No') %>%
  layout(yaxis = list(title = 'Count'), barmode = 'stack')
df52 = sqldf("SELECT PPERSAUT ,count(*) as 'Number' FROM viz_data WHERE CLASS='Yes' GROUP BY PPERSAUT ")
plot_ly(
  labels = ~df52$PPERSAUT ,
  values = ~df52$Number,
  type = "pie"
) %>% layout(title="Contribution Car Policies -> Yes")
```
<br><br>
Dans la partie ci-dessus, nous en venons à savoir que les clients qui paient une prime de police moyenne allant de 1 000 $ à 4 499 $ (6) sont plus susceptibles d’acquérir la police de caravane.
<br><br>
```{r echo=FALSE, messages=FALSE}
df24 = sqldf("SELECT s.APLEZIER   ,(SELECT count(*) FROM viz_data d1 WHERE CLASS='Yes' and s.APLEZIER    = d1.APLEZIER   ) as 'NumberYes',(SELECT count(*) FROM viz_data d2 WHERE CLASS='No' and s.APLEZIER   =d2.APLEZIER   ) as 'NumberNo' FROM viz_data s GROUP BY s.APLEZIER   ")
Numberofboatpolicies <- df24$APLEZIER   
Yes <- df24$NumberYes
No <- df24$NumberNo
datadf24 <- data.frame(Numberofboatpolicies, Yes, No)

plot_ly(datadf24, x = ~Numberofboatpolicies, y = ~Yes, type = 'bar', name = 'Yes') %>%
  add_trace(y = ~No, name = 'No') %>%
  layout(yaxis = list(title = 'Count'), barmode = 'stack')
df114 = sqldf("SELECT APLEZIER,count(*) as 'Number' FROM viz_data WHERE CLASS='Yes' GROUP BY APLEZIER ")
df114 %>%
  plot_ly(labels = ~APLEZIER , values = ~Number) %>%
  add_pie(hole = 0.5) %>%
  layout(showlegend = T,
         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE)) %>% layout(title="Number of boat policies -> Yes")
```
<br><br>
Dans le graphique à barres ci-dessus, nous en venons à savoir que les clients qui n’ont pas souscrit de police d’assurance sociale (0) sont plus susceptibles d’acquérir la police Caravan.
<br><br>
```{r echo=FALSE, messages=FALSE}
df27 = sqldf("SELECT s.MGEMLEEF    ,(SELECT count(*) FROM viz_data d1 WHERE CLASS='Yes' and s.MGEMLEEF     = d1.MGEMLEEF    ) as 'NumberYes',(SELECT count(*) FROM viz_data d2 WHERE CLASS='No' and s.MGEMLEEF    =d2.MGEMLEEF    ) as 'NumberNo' FROM viz_data s GROUP BY s.MGEMLEEF    ")
Avgage <- df27$MGEMLEEF    
Yes <- df27$NumberYes
No <- df27$NumberNo
datadf27 <- data.frame(Avgage, Yes, No)

plot_ly(datadf27, x = ~Avgage, y = ~Yes, type = 'bar', name = 'Yes') %>%
  add_trace(y = ~No, name = 'No') %>%
  layout(yaxis = list(title = 'Count'), barmode = 'stack')

df117 = sqldf("SELECT MGEMLEEF,count(*) as 'Number' FROM viz_data WHERE CLASS='Yes' GROUP BY MGEMLEEF")
df117 %>%
plot_ly(labels = ~MGEMLEEF, values = ~Number) %>%
  add_pie(hole = 0.5) %>%
  layout(showlegend = T,
         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE)) %>% layout(title="Avg Age -> Yes")
```
<br><br>
Dans le graphique à barres ci-dessus, des clients de différents groupes d’âge sont pris et comparés aux clients qui ont dit oui à l’assurance sur d’achat de caravanes. Les clients appartenant au groupe d’âge des 40 à 50 ans sont plus susceptibles d’acquérir la police caravane.
<br><br>
```{r echo=FALSE, message=FALSE}
df223 = sqldf("SELECT s.MOPLMIDD       ,(SELECT count(*) FROM viz_data d1 WHERE CLASS='Yes' and s.MOPLMIDD      = d1.MOPLMIDD       ) as 'NumberYes',(SELECT count(*) FROM viz_data d2 WHERE CLASS='No' and s.MOPLMIDD      =d2.MOPLMIDD      ) as 'NumberNo' FROM viz_data s GROUP BY s.MOPLMIDD      ")
Mediumleveleducation <- df223$MOPLMIDD      
Yes <- df223$NumberYes
No <- df223$NumberNo
datadf223 <- data.frame(Mediumleveleducation, Yes, No)

plot_ly(datadf223, x = ~Mediumleveleducation, y = ~Yes, type = 'bar', name = 'Yes') %>%
  add_trace(y = ~No, name = 'No') %>%
  layout(yaxis = list(title = 'Count'), barmode = 'stack')
df115 = sqldf("SELECT MOPLMIDD,count(*) as 'Number' FROM viz_data WHERE CLASS='Yes' GROUP BY MOPLMIDD")
p <- df115 %>%
plot_ly(labels = ~MOPLMIDD, values = ~Number) %>%
  add_pie(hole = 0.5) %>%
  layout(showlegend = T,
         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE)) %>% layout(title="Medium Level Education -> Yes")
```
<br><br>
Dans la partie ci-dessus, nous en venons à savoir que les clients qui une education moyenne sont plus susceptibles d’acheter l’assurance sur Caravane.
<br><br>
```{r echo=FALSE, messages=FALSE}
df20 = sqldf("SELECT s.MHKOOP       ,(SELECT count(*) FROM viz_data d1 WHERE CLASS='Yes' and s.MHKOOP      = d1.MHKOOP       ) as 'NumberYes',(SELECT count(*) FROM viz_data d2 WHERE CLASS='No' and s.MHKOOP      =d2.MHKOOP      ) as 'NumberNo' FROM viz_data s GROUP BY s.MHKOOP      ")
Homeowners <- df20$MHKOOP      
Yes <- df20$NumberYes
No <- df20$NumberNo
datadf20 <- data.frame(Homeowners, Yes, No)

plot_ly(datadf20, x = ~Homeowners, y = ~Yes, type = 'bar', name = 'Yes') %>%
  add_trace(y = ~No, name = 'No') %>%
  layout(yaxis = list(title = 'Count'), barmode = 'stack')
df50 = sqldf("SELECT MHKOOP ,count(*) as 'Number' FROM viz_data WHERE CLASS='Yes' GROUP BY MHKOOP ")
plot_ly(
  labels = ~df50$MHKOOP ,
  values = ~df50$Number,
  type = "pie"
) %>% layout(title="Home Owners -> Yes")
```
<br><br>
Dans la partie ci-dessus, nous en venons à savoir que les clients qui ont un revenu>30K sont plus susceptibles d’acheter l’assurance sur Caravane.
<br><br>
```{r echo=FALSE, messages=FALSE}
df521 = sqldf("SELECT \"MINKM30.\"  ,count(*) as 'Number' FROM viz_data WHERE CLASS='Yes' GROUP BY \"MINKM30.\"  ")
plot_ly(
  labels = ~df521$MINKM30  ,
  values = ~df521$Number,
  type = "pie"
) %>% layout(title="Income < 30.000 -> Yes")
df512 = sqldf("SELECT ABRAND  ,count(*) as 'Number' FROM viz_data WHERE CLASS='Yes' GROUP BY ABRAND  ")
plot_ly(
  x = df512$ABRAND  ,
  y = df512$Number,
  type = "bar"
) %>% layout(title="Number of fire policies -> Yes")
```
<br><br>
Dans la partie ci-dessus, nous en venons à savoir que les clients qui achètent une seule politique incendie sont plus susceptibles d’acheter l’assurance sur Caravane.
<br><br>
```{r echo=FALSE, messages=FALSE}
car_policies = sqldf("SELECT count(*) as 'car_policies' FROM viz_data WHERE CLASS='Yes' AND APERSAUT <>'0'  ")
Income_30K = sqldf("SELECT count(*) as 'Income_30K' FROM viz_data WHERE CLASS='Yes' AND \"MINKM30.\" <>'0%'  ")
moped_policies = sqldf("SELECT count(*) as 'moped_policies' FROM viz_data WHERE CLASS='Yes' AND PBROM  <>'0' ")
fire_policies = sqldf("SELECT count(*) as 'fire_policies' FROM viz_data WHERE CLASS='Yes' AND PBRAND  <>'0' ")
Lower_level_education = sqldf("SELECT count(*) as 'Lower_level_education' FROM viz_data WHERE CLASS='Yes' AND MOPLLAAG  <>'0' ")
Count = c( car_policies  ,  Income_30K  , moped_policies , fire_policies  , Lower_level_education )

dat <- data.frame(
  Selected_Features = factor(c("car_policies" , "Income_30K " , "moped_policies" , "fire_policies"  , "Lower_level_education" ), levels=c("car_policies" , "Income_30K " , "moped_policies" , "fire_policies"  , "Lower_level_education")),
  Count 
)

ggplot(data=dat, aes(x=Selected_Features, y=Count, fill=Selected_Features)) +
  geom_bar(colour="black", stat="identity")
```
<br><br>
On peut observer que les clients actuels des polices de voiture et des polices de feu ont également tendance à acheter «l’assurance pour Caravane». De plus, la population de la classe de réussite est généralement lower_level_education et Income_30K. Examinons plus de fonctionnalités de la classe de réussite.
<br><br>
```{r echo=FALSE, messages=FALSE}
No_of_boat_policies <- sqldf("SELECT count(*) as 'No_of_boat_policies' FROM viz_data WHERE CLASS='Yes' AND APLEZIER<>'0'  ")
Married <- sqldf("SELECT count(*) as 'Married' FROM viz_data WHERE CLASS='Yes' AND MRELGE<>'0'  ")
Other_relation <- sqldf("SELECT count(*) as 'Other_relation' FROM viz_data WHERE CLASS='Yes' AND MRELOV<>'0%'  ")
boat_policies <- sqldf("SELECT count(*) as 'boat_policies' FROM viz_data WHERE CLASS='Yes' AND PPLEZIER<>'0'  ")
Skilled_labourers <- sqldf("SELECT count(*) as 'Skilled_labourers' FROM viz_data WHERE CLASS='Yes' AND MBERARBG<>'0%' ")

Lower_level_education <- sqldf("SELECT count(*) as 'Lower_level_education' FROM viz_data WHERE CLASS='Yes' AND MOPLLAAG <> '0%' ")

Count = c(No_of_boat_policies, Married , Other_relation , boat_policies , Skilled_labourers, Lower_level_education)

  
dat1 <- data.frame(
  Selected_Features = factor(c("No_of_boat_policies","Married" , "Other_relation" , "boat_policies" , "Skilled_labourers"  , "Lower_level_education" ), levels=c("No_of_boat_policies","Married" , "Other_relation" , "boat_policies" , "Skilled_labourers"  , "Lower_level_education")),
  Count
)

ggplot(data=dat1, aes(x=Selected_Features, y=Count, fill=Selected_Features)) +
  geom_bar(colour="black", stat="identity")
```
<br><br>
Les deux graphiques ci-dessus sont basés sur les caractéristiques indiquées comme importants de notre analyse.

## Préparation des données (avec du retour en arrière pour la compréhension des données, CRISP appliqué)

Un premier examen des données a révélé que, pour les paramètres de religion, ces clients qui sont catholiques romains sont ensuite subdivisés en 10 niveaux différents avec une gamme de valeurs en pourcentage.
Malgré diverses tentatives pour obtenir plus d’informations sur que représente la valeur en pourcentage en fait pour un paramètre qui aurait normalement une simple valeur binaire, c’est-à-dire si quelqu'un est catholique ou non, nous avons été incapables de trouver une crédible explication. Compte tenu de ce manque de clarté, il a été décidé d’exclure les quatre domaines liés à la religion.
Cependant, avant ce faisant, nous avons effectué une analyse de corrélation pour nous assurer que ces quatre paramètres de religion ne sont pas en corrélation significative avec les détenteurs d’assurance caravane. Pour la corrélation entre la religion des clients associée à Caravan Insurance, la commande R suivante a été utilisé:
```{r echo=FALSE, messages=FALSE, results='hide'}
str(prepared_data)
prepared_data$CLASS <- as.integer(prepared_data$CLASS)
prepared_data[which(prepared_data$CLASS == 2),]$CLASS <- 0
prepared_data[which(prepared_data$CLASS == 0),]
```
```{r results='hide'}
cor(prepared_data[1:85], prepared_data$CLASS)
```
<br>
Pour les variables concernant les religions des clients de l'assurance étudiée.
<br>
```{r echo=FALSE}
cor(prepared_data[c(6,7,8,9)], prepared_data$CLASS)
```
<br>
Comme on peut le voir dans ce tableau de corrélation, les corrélations entre la religion des clients et la détention de l'assurance sur caravane ne sont pas très significatives. Par conséquent, sur la base de cela, les quatre paramètres de religion ont été exclus de l'analyse plus détaillée présentée ici. Cela a réduit le nombre total de variables à 82.
```{r echo=FALSE}
prepared_data$SD6 <- NULL
prepared_data$SD7 <- NULL
prepared_data$SD8 <- NULL
prepared_data$SD9 <- NULL
```
<br>
Avant d’explorer de plus en plus l’ensemble de données, chacune des quatre variables catégoriques restantes a été «déployée» (c’est-à-dire convertie en une variable binaire). Par exemple, la première variable catégorielle, MOSTYPE, qui définit le «sous-type de client» comportait 41 niveaux, tels que «carrière et garde d'enfants» ou «famille de classe moyenne». Chaque sous-type est traité comme une variable distincte avec une valeur binaire indiquant si un client appartient à ce sous-type ou non. Cela a augmenté le nombre total de variables de 82 à 155 (sans compter les 5 remplacées).
```{r}
# Renaming the factorial columns so then we can unfold them without harming the other colunmns
colnames(prepared_data)[colnames(prepared_data)=="SD1"] <- "MOSTYPE"
colnames(prepared_data)[colnames(prepared_data)=="SD2"] <- "MAANTHUI"
colnames(prepared_data)[colnames(prepared_data)=="SD3"] <- "MGEMOMV"
colnames(prepared_data)[colnames(prepared_data)=="SD4"] <- "MGEMLEEF"
colnames(prepared_data)[colnames(prepared_data)=="SD5"] <- "MOSHOOFD"

# Factoring studied variables
prepared_data$MOSTYPE <- as.factor(prepared_data$MOSTYPE)
prepared_data$MAANTHUI <- as.factor(prepared_data$MAANTHUI)
prepared_data$MGEMOMV <- as.factor(prepared_data$MGEMOMV)
prepared_data$MGEMLEEF <- as.factor(prepared_data$MGEMLEEF)
prepared_data$MOSHOOFD <- as.factor(prepared_data$MOSHOOFD)

# Fixing missing levels
levels(prepared_data$MOSTYPE) <- c(levels(prepared_data$MOSTYPE), "14")
levels(prepared_data$MAANTHUI) <- c(levels(prepared_data$MAANTHUI), "9")

# unfolding and binding variables to dataframe
m1 <- model.matrix( ~ MOSTYPE - 1, data=prepared_data )
m2 <- model.matrix( ~ MAANTHUI - 1, data=prepared_data )
m3 <- model.matrix( ~ MGEMOMV - 1, data=prepared_data )
m4 <- model.matrix( ~ MGEMLEEF - 1, data=prepared_data )
m5 <- model.matrix( ~ MOSHOOFD - 1, data=prepared_data )
m_unfolded <- cbind(m1,m2)
m_unfolded <- cbind(m_unfolded, m3)
m_unfolded <- cbind(m_unfolded, m4)
m_unfolded <- cbind(m_unfolded, m5)
prepared_data <- cbind(prepared_data, m_unfolded)
```
<br>
On obtient ainsi un tel résultat pour notre trâme résultante:
<br>
```{r echo=FALSE, messagea=FALSE}
kable(tail(prepared_data[143:150], 5), caption = "Visualisation de quelques colonnes pour une meilleure lisibilité") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```
<br>
L'ensemble de données de formation avec 145 variables a été soumis à une analyse exploratoire plus poussée des données. La commande R suivante a été utilisée pour obtenir un aperçu de la valeur de chaque variable de profil client:
Encore pour une meilleure lisibilité, on ne va inclure dans ce rapport qu'une partie de la description obtenue:
<br>
```{r results='hide'}
describe(prepared_data)
```
```{r echo=FALSE}
describe(prepared_data[1:2])
```
<br>
Cette analyse a fourni des informations détaillées sur la nature des données du profil du client. En particulier, il indique clairement le nombre de clients entrant dans chaque sous-type des quatre principales variables catégorielles. Par exemple, dans le tableau détaillé, il est clair que la répartition des clients dans chaque sous-type de client n'est pas uniforme. Il est intéressant de noter qu’il n’ya pas de clients appartenant au sous-type «Junior Cosmopolitan» ou «Students in apartment», ce qui est quelque peu corroboré par le nombre relativement très bas de clients du groupe d’âge «20-30 ans».
Pour voir s'il existe une relation particulièrement forte entre les paramètres du client
et d’assurance caravane, nous avons décidé d’examiner la proportion de détenteurs d’assurance caravane par rapport à chacune des variables restantes (indépendantes). La commande R suivante a été utilisée pour cette analyse:
<br>
```{r results='hide'}
for (i in colnames(prepared_data))
  print(prop.table(table(prepared_data[,i], prepared_data$CLASS), 1))
```
```{r echo=FALSE}
cat("Pour la taille moyenne des ménages", "\n")
prop.table(table(prepared_data$MGEMOMV, prepared_data$CLASS))
cat("Pour l'age moyen", "\n")
prop.table(table(prepared_data$MGEMLEEF, prepared_data$CLASS))
```
<br>
Les résultats ne signifiaient aucun autre lien entre l'assurance de la caravane et toute autre variable spécifique. Dans l’ensemble, les résultats ont également confirmé le nombre relativement faible de titulaires de polices d’assurance caravane dans la base de données.
Après avoir exploré les dépendances entre les variables, nous avons effectué une analyse de régression logistique linéaire comme suit:
<br>
```{r}
prepared_data <- viz_data
prepared_data$CLASS <- as.integer(prepared_data$CLASS)
prepared_data[which(prepared_data$CLASS == 1),]$CLASS <- 0
prepared_data[which(prepared_data$CLASS == 2),]$CLASS <- 1
cust.logit <- glm(formula = CLASS~., data = prepared_data)
options(max.print=1000000)
summary(cust.logit)
```
<br>
Il est intéressant de noter que toutes les variables sauf une (primes) des polices détenues par les clients. Cela implique que les assurés de la caravane sont très susceptibles de posséder d'autres polices d'assurance. Cette constatation n’est pas surprenante et n’est pas particulièrement éclairante car les données concernent les clients existants.
Il convient également de noter que les clients ayant une politique de navigation de plaisance et de planche de surf et des revenus élevés (supérieurs à 125 000) sont plus susceptibles d’avoir une politique de caravane, segment de clientèle axé sur les activités de plein air. Nous verrons ci-dessous l'inclusion de «faible niveau d'éducation», qui est un indicateur intéressant d'un autre groupe qui pourrait également avoir une assurance caravane.

Le modèle d'analyse de données exploratoire et de régression logistique (RL) présenté ici a fourni des résultats intéressants, mais aucune idée nouvelle susceptible d'avoir un impact significatif sur le marketing ciblé de l'assurance caravane. En d'autres termes, ils soulignent l'évident; les clients avec plus de polices et (donc) de contributions, ainsi que le temps et l'argent consacrés aux activités de loisirs sont également plus susceptibles de souscrire des polices d'assurance caravane. Bien que ces informations puissent être utiles pour cibler des clients potentiels, elles sont néanmoins assez prévisibles.
Pour atteindre notre objectif de recherche d'un profil de client non évident, il a été décidé de construire ou d'apprendre des modèles prédictifs. On s’attendait à ce que les informations fournies par ces modèles soient utiles pour développer une campagne marketing plus nuancée visant un profil de client (c’est-à-dire des acheteurs) qui n’aurait pas été ciblée autrement.
Après visualisation de l'importance des variables dans notre classification/profil client, on va donc essayer de les ordonner suivant leurs degrés d'importance:
<br>
```{r eval=FALSE}
# ensure results are repeatable
set.seed(7)
prepared_data <- viz_data
# prepare training scheme
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(CLASS~., data=prepared_data, method="rpart", preProcess="scale", trControl=control)
# estimate variable importance
importance <- varImp(model, scale=FALSE)
```
<br>
Les méthodes de sélection automatique de caractéristiques peuvent être utilisées pour créer de nombreux modèles avec différents sous-ensembles d'un jeu de données et pour identifier les attributs qui sont et ne sont pas nécessaires pour créer un modèle précis.

Une méthode automatique populaire pour la sélection des fonctionnalités fournie par le package caret R est appelée élimination des fonctionnalités récursives ou RFE.
<br>
```{r eval=FALSE}
# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(prepared_data[,1:85], prepared_data[,86], sizes=c(1:85), rfeControl=control)
# summarize the results
print(results)
# list the chosen features
predictors(results)
# plot the results
plot(results, type=c("g", "o"))
```
<br>
Et par surprise, l'élimination récursive des traits nous a donné un résultat se rapprochant de celui du modèle de régression logistique. (Se rapprochant, vu que par la sélection aléatoire à l'évaluation des traits, la sélection de deux traits dépendants laissera celui sélectionné en premier)
<br>
```{r echo=FALSE, message=FALSE, results='hide', warning=FALSE}
prepared_data <- raw_data
```
```{r message=FALSE, results=FALSE, warning=FALSE}
prepared_data$CLASS<-relevel(prepared_data$CLASS,"Yes")
learning.Set<-prepared_data[which(prepared_data$STATUS=="Learning"),]
test.Set<-prepared_data[which(prepared_data$STATUS=="Test"),]

learning.Set<-learning.Set[,1:86]
test.Set<-test.Set[,1:86]

modele<-glm(CLASS~ 1,data = learning.Set,family = binomial)
str_constant <- "~ 1"
str_all <- "~SD1+SD2+SD3+SD4+SD5+SD6+SD7+SD8+SD9+SD10+SD11+SD12+SD13+SD14+SD15+SD16+SD17+SD18+SD19+SD20+SD21+SD22+SD23+SD24+SD25+SD26+SD27+SD28+SD29+SD30+SD31+SD32+SD33+SD34+SD35+SD36+SD37+SD38+SD39+SD40+SD41+SD42+SD43+PO44+PO45+PO46+PO47+PO48+PO49+PO50+PO51+PO52+PO53+PO54+PO55+PO56+PO57+PO58+PO59+PO60+PO61+PO62+PO63+PO64+PO65+PO66+PO67+PO68+PO69+PO70+PO71+PO72+PO73+PO74+PO75+PO76+PO77+PO78+PO79+PO80+PO81+PO82+PO83+PO84+PO85"

mod2<-stepAIC(modele, data=learning.Set,scope = list(lower = str_constant, upper = str_all),trace = TRUE,direction = "both")
```
```{r echo=FALSE}
summary(mod2)
```
<br>
C'est ainsi qu'on se cèdera de ces variables pour la construction de notre modèle de classification et pour le scoring des clients pour obtenir leurs degrés d'appétance.
<br>
```{r echo=FALSE}
final_features_data <- prepared_data[, c("PO47", "SD43", "PO59", "PO82", "SD18", "SD21", "SD10", "PO46", "PO83", "SD41", "SD42",
                                         "PO58", "SD4", "PO44", "PO85", "PO80", "PO74", "SD7", "PO79", "SD28", "SD16", "SD22", "CLASS")]
```

## Modélisation et extraction de profil

On s'intéressera maintenant à la création d'un modèle performant de classification et à l'affectation du degré d'appétance à la clientèle en utilisant nos traits présélectionnés par le degré d'importance et la signification en terme de métirer.
Pour ce faire, on se cèdera par une méthode de machine learning avancé, qui est le 'model stacking' et qui est une technique très utilisé en marketing ciblé pour l'optimisation de la sélection des profils intéressants et de l'affectation de score.
Commencons donc par le Boosting, on se cèddera des deux plus importants algorithmes connus qui sont le Gradient Boosting stochastique et le C5.0:
```{r message=FALSE, results='hide', eval=FALSE}
control <- trainControl(method="repeatedcv", number=10, repeats=3)
seed <- 7
metric <- "Accuracy"
# C5.0
set.seed(seed)
fit.c50 <- train(CLASS~., data=final_features_data, method="C5.0", metric=metric, trControl=control)
# Stochastic Gradient Boosting
set.seed(seed)
fit.gbm <- train(CLASS~., data=final_features_data, method="gbm", metric=metric, trControl=control, verbose=FALSE)
# summarize results
boosting_results <- resamples(list(c5.0=fit.c50, gbm=fit.gbm))
```
```{r eval=FALSE}
summary(boosting_results)
dotplot(boosting_results)
```
<br>
On peut remarquer ainsi que l'algorithme du gradient boosting stochastique produit un modèle plus précis pour le Boosting.
Passons alors au Bagging, on essaiera le Bagging CART et le Random Forest biensur.
<br>
```{r message=FALSE, results='hide', eval=FALSE}
control <- trainControl(method="repeatedcv", number=10, repeats=3)
seed <- 7
metric <- "Accuracy"
# Bagged CART
set.seed(seed)
fit.treebag <- train(CLASS~., data=final_features_data, method="treebag", metric=metric, trControl=control)
# Random Forest
set.seed(seed)
fit.rf <- train(CLASS~., data=final_features_data, method="rf", metric=metric, trControl=control)
# summarize results
bagging_results <- resamples(list(treebag=fit.treebag, rf=fit.rf))
```
```{r eval=FALSE}
summary(bagging_results)
dotplot(bagging_results)
```
<br>
Comme on peut le voir donc en exécutant le code approprié, la technique de bagging par le random forest nous produit une précision plus èlevée que le tree bagging donc on se cèdera de cette technique.
Passons finalement, à la création du modèle:
Étant donné une liste de modèles de caret, la fonction caretStack () peut être utilisée pour spécifier un modèle d'ordre supérieur afin d'apprendre à combiner au mieux les prédictions de sous-modèles.

Voyons d’abord la création de 5 sous-modèles pour le jeu de données sur l’ionosphère, à savoir:

Analyse linéaire discriminante (LDA)
Arbres de classification et de régression (CART)
Régression logistique (via modèle linéaire généralisé ou GLM)
k-voisins les plus proches (kNN)
Prise en charge de la machine à vecteurs avec fonction de noyau à base radiale (SVM)
<br>
```{r message=FALSE, eval=FALSE}
control <- trainControl(method="repeatedcv", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)
algorithmList <- c('lda', 'rpart', 'glm', 'knn', 'svmRadial')
set.seed(seed)
models <- caretList(CLASS~., data=final_features_data, trControl=control, methodList=algorithmList)
results <- resamples(models)
summary(results)
dotplot(results)
```
<br>
Nous pouvons voir que le SVM crée le modèle le plus précis avec une précision de 96,47%.
Lorsque nous combinons les prédictions de différents modèles en utilisant l'empilement, il est souhaitable que les prédictions faites par les sous-modèles aient une faible corrélation. Cela suggérerait que les modèles sont habiles mais de différentes manières, permettant ainsi à un nouveau classificateur de déterminer comment tirer le meilleur parti de chaque modèle pour obtenir un score amélioré.

Si les prévisions pour les sous-modèles étaient fortement corrigées (> 0,75), ils feraient alors des prévisions identiques ou très similaires, réduisant le plus souvent l'avantage de la combinaison des prévisions.
<br>
```{r eval=FALSE, message=FALSE}
# correlation between results
modelCor(results)
splom(results)
```
<br>
Nous pouvons voir que toutes les paires de prédictions ont généralement une faible corrélation. Les deux méthodes présentant la plus forte corrélation entre leurs prédictions sont la régression logistique (GLM) et kNN à une corrélation de 0,428, ce qui n’est pas considéré comme élevé (> 0,75).
Combinons les prédictions des classificateurs à l’aide d’un modèle linéaire simple.
<br>
```{r eval=FALSE, message=FALSE}
# stack using glm
stackControl <- trainControl(method="repeatedcv", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)
set.seed(seed)
stack.glm <- caretStack(models, method="glm", metric="Accuracy", trControl=stackControl)
print(stack.glm)
```
<br>
Nous pouvons constater que nous avons porté la précision à 96,99%, ce qui représente une légère amélioration par rapport à l'utilisation de SVM seul. Ceci constitue également une amélioration par rapport à l'utilisation de la forêt aléatoire uniquement sur l'ensemble de données, comme indiqué ci-dessus.
Nous pouvons également utiliser des algorithmes plus sophistiqués pour combiner les prévisions afin de déterminer le meilleur moment pour utiliser les différentes méthodes. Dans ce cas, nous pouvons utiliser l'algorithme de forêt aléatoire pour combiner les prédictions.
<br>
```{r eval=FALSE, message=FALSE}
# stack using random forest
set.seed(seed)
stack.rf <- caretStack(models, method="rf", metric="Accuracy", trControl=stackControl)
print(stack.rf)
```
<br>
Nous pouvons voir que cela a élevé la précision à 98,56%, une amélioration impressionnante en RF seulement.

## Conclusion pour la modélisation et l'optimisation:

Après qu'on a essayé toutes les trois méthodes de création d'un modèle optimisé pour la classification en se basant sur nos traits clientèles sélectionnés, on a trouvé que la technique du stacking est celle qui nous a donné le meilleur modèle en terme d'identification de l'appétance des clients, reste maintenant à définir un algorithme d'affectation de score qui représentera le degré d'appétance du client pour cette police d'assurance sur caravane.
Pour ce faire, on s'intéressera biensûr aux traits clientels, On définira ainsi le profil clientel ciblé par le meilleur profil sélectionné ou classifié en un NON pour le trait "CLASSE" (par le meilleur profil, on veut dire le profil le plus proche à la classe "OUI" en terme de probabilité d'appartenance accordé par le modèle), après, le score ou le degré d'appétance sera pondéré par le pourcentage de vraisemblance entre ce profil et le profil du client étudié, donc s'il s'agit d'une classification en un "OUI" par notre modèle établi, on n'y modifiera pas le score, ou même on peut lui affecter un 1 comme score, vu qu'on est intéressé le plus par ceux qui sont classés en un "NON" mais ont une faible probabilité d'appartenance à leur classe, donc on teste la vraisemblance de ce profil avec le profil typique (en terme de valeur et modalités des traits sélectionnés) et on lui affecte son score.
<br>
$$ Profil(client) = \Sigma coef(i)*var(i)[bool(client)]$$
les coefficients et les variables étant ceux définies par le modèle de la régression logistique.
bool(client) sera définie par les valeurs des attributs en question du Profil(typ) sachant que c'est celui classé Oui avec le maximum de probabilité d'appartenance à la classe Oui.

Pa <- Probabilité d'appartenance (déterminée par le modèle)
C <- Classe prédite (Yes = 1, No = 0)
$$ Score(client) = C+[1-C][(1 - Pa) *(1/2) + Profil(client) / Profil(typ)*(1/2)]$$
<br>

## Conclusion

L’analyse ci-dessus et le développement du modèle ont été réalisés afin d’obtenir un profil client typique des détenteurs de polices d’assurance Caravan. Pour atteindre cet objectif, nous avons développé des modèles utilisant des méthodes de classification différentes.
Le principal objectif du développement d’un profil de client cible est de l’utiliser pour identifier correctement les clients potentiels. Un modèle permettant de les identifier avec précision augmenterait le taux de réussite d'une campagne marketing.
Nous nous attendons à ce que des améliorations plus poussées dans le processus de création de modèles permettent de développer des modèles aussi perspicaces. Un moyen d'y parvenir consiste à explorer les moyens de supprimer ou de regrouper des données relatives à des polices d'assurance. Comme nous l'avons déjà noté, tous les modèles incluent des variables telles que les «stratégies de nombre de wagons» ou «stratégies de wagons de contribution». La raison en est leur prépondérance dans l'ensemble de données; environ un tiers de toutes les variables concernent le nombre ou la contribution aux politiques. Étant donné que ces deux types de variables sont essentiellement deux aspects d’un seul (type) de police d’assurance, il est possible d’en écarter une et de développer des modèles avec un ensemble de données réduit. Une analyse préliminaire de corrélation par paire entre Nombre et Contribution semble suggérer que cela serait réalisable sans perte significative d'informations. Les modèles de classificateur basés sur un ensemble de données de variables aussi réduit auront probablement moins de variables indépendantes, ce qui serait particulièrement le cas pour un modèle empilé basé sur SVM.
